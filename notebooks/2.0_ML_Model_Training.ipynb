{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "481005d1",
   "metadata": {},
   "source": [
    "# 2.0 Automobile Sales Classification Model Training\n",
    "\n",
    "This notebook documents the final steps in the data pipeline: loading the raw data, performing final feature engineering, and training the **Logistic Regression Model** used to classify \"Successful Sales\" for the dashboard visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ea90f8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "\n",
    "# --- PATH SETUP ---\n",
    "# We use the parent directory (..) to navigate from 'notebooks/' to 'data/'\n",
    "PROCESSED_DATA_PATH = '../data/processed/cleaned_data.csv'\n",
    "RAW_DATA_PATH = '../data/raw/auto_sales_raw.csv'\n",
    "MODEL_PATH = '../data/model/classification_model.pkl'\n",
    "\n",
    "# Load the raw data file (We assume this file exists from the setup_pipeline_data.py run)\n",
    "try:\n",
    "    # If the setup script was run, the raw data exists, even if we focus on cleaning it now\n",
    "    df = pd.read_csv(RAW_DATA_PATH)\n",
    "    print(f\"Data loaded successfully from {RAW_DATA_PATH}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"ERROR: Raw data file not found. Please ensure the data setup script has been executed.\")\n",
    "    exit()\n",
    "\n",
    "print(\"\\nInitial Data Head:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b4aeaa",
   "metadata": {},
   "source": [
    "## Feature Engineering and Target Variable Encoding\n",
    "\n",
    "We must prepare all categorical features (Manufacturer, Region, TimePeriod) for the ML model by encoding them numerically. Critically, we encode the `Success_Category` target variable into binary form (0 or 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faab703",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Convert Price to a numerical type\n",
    "df['Price_k'] = df['Price_k'].astype(float)\n",
    "\n",
    "# --- Feature Engineering ---\n",
    "# 1. Encode categorical features (Manufacturer, Region, TimePeriod)\n",
    "le = LabelEncoder()\n",
    "df['Manufacturer_Encoded'] = le.fit_transform(df['Manufacturer'])\n",
    "df['Region_Encoded'] = le.fit_transform(df['Region'])\n",
    "df['TimePeriod_Encoded'] = le.fit_transform(df['TimePeriod'])\n",
    "\n",
    "# 2. Encode the target variable (Success_Category) into binary (1 for Success, 0 for Unsuccessful)\n",
    "df['Success_Target'] = df['Success_Category'].apply(\n",
    "    lambda x: 1 if x == 'Successful Sales' else 0\n",
    ")\n",
    "\n",
    "# Define the final DataFrame used by the dashboard\n",
    "cleaned_df = df[[\n",
    "    'Manufacturer', 'Region', 'TimePeriod', 'SalesVolume', \n",
    "    'Price_k', 'Sales_Category', 'Success_Target'\n",
    "]]\n",
    "\n",
    "print(\"Features Engineered and Target Variable Encoded.\")\n",
    "print(\"\\nCleaned Data Sample:\")\n",
    "print(cleaned_df.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f646db",
   "metadata": {},
   "source": [
    "## Training the Logistic Regression Model\n",
    "\n",
    "We split the data and train the **Logistic Regression** model. This model's success rate prediction is displayed on the dashboard's KPI card and in the pie chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5a9d87",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Define Features (X) and Target (y)\n",
    "features = ['SalesVolume', 'Price_k', 'Manufacturer_Encoded', 'Region_Encoded', 'TimePeriod_Encoded']\n",
    "X = df[features]\n",
    "y = df['Success_Target']\n",
    "\n",
    "# Split data for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Logistic Regression Model\n",
    "model = LogisticRegression(solver='liblinear', random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Model Evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Model Training Complete.\")\n",
    "print(f\"Logistic Regression Model Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dbec89",
   "metadata": {},
   "source": [
    "## Saving Artifacts\n",
    "\n",
    "The final, crucial step is saving both the processed data and the trained model artifact (`.pkl` file). These are the exact files loaded by the Dash application (`app/app.py`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3621c5da",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Save the cleaned DataFrame to the processed data folder\n",
    "cleaned_df.to_csv(PROCESSED_DATA_PATH, index=False)\n",
    "print(f\"Cleaned data saved to: {PROCESSED_DATA_PATH}\")\n",
    "\n",
    "# Save the trained model using pickle\n",
    "with open(MODEL_PATH, 'wb') as file:\n",
    "    pickle.dump(model, file)\n",
    "print(f\"Trained ML Model saved to: {MODEL_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
